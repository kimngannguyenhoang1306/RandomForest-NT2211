{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**MỤC TIÊU TỔNG QUÁT**\n",
        "\n",
        "**1. Xử lý dữ liệu đầu vào:**\n",
        "\n",
        "Xử lý giá trị thiếu cho các cột số và cột phân loại.\n",
        "Mã hóa các cột phân loại thành dạng số để mô hình có thể sử dụng.\n",
        "Chuẩn hóa dữ liệu để cải thiện hiệu suất mô hình.\n",
        "\n",
        "**2. Huấn luyện mô hình:**\n",
        "\n",
        "Sử dụng thuật toán Random Forest Classifier để xây dựng mô hình.\n",
        "Thực hiện đánh giá hiệu suất bằng Cross-Validation.\n",
        "Lưu lại các báo cáo chi tiết về hiệu suất mô hình.\n",
        "\n",
        "**3. Tối ưu hóa mô hình:**\n",
        "\n",
        "Dùng GridSearchCV để tìm kiếm các tham số tối ưu.\n",
        "Đảm bảo rằng mô hình đạt được hiệu suất cao nhất trên tập dữ liệu huấn luyện.\n",
        "\n",
        "**4. Lưu trữ và sử dụng lại:**\n",
        "\n",
        "Lưu mô hình, scaler (chuẩn hóa dữ liệu), label encoder (mã hóa nhãn) để tái sử dụng trong tương lai.\n",
        "Lưu lại các kết quả dự đoán từ tập dữ liệu kiểm tra.\n",
        "\n",
        "**5. Ghi log và báo cáo:**\n",
        "\n",
        "Ghi lại quá trình thực thi vào file log, giúp dễ dàng theo dõi hoặc debug.\n",
        "Tạo báo cáo chi tiết về mô hình (bằng Markdown), bao gồm hiệu suất và tham số."
      ],
      "metadata": {
        "id": "mu5_7XXclzG8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Đoạn code sau thực hiện:\n",
        "*   Kết nối Google Drive với Google Colab để truy cập dữ liệu lưu trữ trong Drive.\n",
        "*   Tải file lên từ máy tính cá nhân nếu dữ liệu không có sẵn trên Google Drive.\n",
        "*   Đọc file CSV từ Google Drive bằng thư viện pandas để chuẩn bị dữ liệu cho các bước xử lý hoặc phân tích tiếp theo."
      ],
      "metadata": {
        "id": "Z10yFCx2mW8U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goywU_Qpi4K_"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "# Sau khi tải file lên, đọc file bằng pandas\n",
        "import pandas as pd\n",
        "df = pd.read_csv('drive/MyDrive/ML/RandomForest/train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulJu6shWIFh4"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Sau khi tải file lên, đọc file bằng pandas\n",
        "import pandas as pd\n",
        "df = pd.read_csv('drive/MyDrive/ML/RandomForest/test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import các thư viện\n",
        "\n",
        "*   Sử dụng pandas và numpy để xử lý dữ liệu\n",
        "*   sklearn để xây dựng và đánh giá mô hình machine learning\n",
        "*   joblib để lưu/tải mô hình\n",
        "*   logging để ghi log quá trình training\n",
        "*   pathlib và os để xử lý đường dẫn file\n",
        "*   warnings để kiểm soát cảnh báo\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2KQywUOWm9ha"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-LP292fZ3-l"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import joblib\n",
        "import logging\n",
        "from pathlib import Path\n",
        "import datetime\n",
        "import os\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Khởi tạo lớp MLPipeline\n",
        "\n",
        "Lớp MLPipeline là trung tâm của pipeline này, đảm nhiệm các công việc từ xử lý dữ liệu, huấn luyện, tối ưu hóa mô hình đến lưu trữ kết quả.\n",
        "\n",
        "1. Hàm setup_logging():\n",
        "Đảm bảo mọi thông tin quan trọng trong quá trình thực thi được lưu trữ và theo dõi.\n",
        "\n",
        "2. Hàm load_data():\n",
        "Đảm bảo rằng dữ liệu đầu vào từ các file CSV được kiểm tra, đọc đúng định dạng và trả về kết quả hợp lệ.\n",
        "\n",
        "3. Hàm preprocess_data():\n",
        "Xử lý dữ liệu một cách hệ thống, bao gồm điền giá trị thiếu, chuẩn hóa và mã hóa.\n",
        "\n",
        "4. Hàm train_random_forest():\n",
        "Huấn luyện mô hình cơ bản và đánh giá hiệu suất bằng Cross-Validation.\n",
        "\n",
        "5. Hàm optimize_random_forest():\n",
        "Tìm tham số tối ưu cho mô hình Random Forest thông qua GridSearchCV.\n",
        "\n",
        "6. Hàm save_artifacts():\n",
        "Quản lý và lưu trữ các artifacts như mô hình, scaler, label encoder và dự đoán.\n",
        "\n",
        "7. Hàm run_pipeline():\n",
        "Chạy toàn bộ pipeline từ đầu đến cuối, kết hợp các bước trên một cách tự động."
      ],
      "metadata": {
        "id": "vLxhfRGWn5tl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIsDJYINZw-z"
      },
      "outputs": [],
      "source": [
        "class MLPipeline:\n",
        "    def __init__(self, random_state=42, n_jobs=None):\n",
        "        #random_state=42: Đặt seed ngẫu nhiên để đảm bảo kết quả có thể tái hiện.\n",
        "        #n_jobs=None: Số luồng (CPU cores) để chạy. Nếu không được cung cấp, nó mặc định là một nửa số nhân CPU.\n",
        "        #self.setup_logging(): Gọi hàm thiết lập logging để lưu trữ nhật ký (logs).\n",
        "        self.random_state = random_state\n",
        "        self.n_jobs = n_jobs if n_jobs is not None else max(os.cpu_count() // 2, 1)\n",
        "        self.setup_logging()\n",
        "\n",
        "    #Thiết lập logging với cấu hình ghi thông tin vào tệp và hiển thị trên console, sử dụng timestamp để lưu tên file\n",
        "    def setup_logging(self):\n",
        "        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "        logging.basicConfig(\n",
        "            level=logging.INFO,\n",
        "            format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "            handlers=[\n",
        "                logging.FileHandler(f'training_{timestamp}.log'),\n",
        "                logging.StreamHandler()\n",
        "            ]\n",
        "        )\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "    # Tạo report đánh giá (bao gồm các bước thực hiện)\n",
        "    def generate_evaluation_report(self, model, cv_scores, best_params=None):\n",
        "        \"\"\"\n",
        "        Generate a comprehensive evaluation report for the model.\n",
        "        \"\"\"\n",
        "        report = \"\"\"\n",
        "# Random Forest Model Evaluation Report\n",
        "\n",
        "## 1. Model Performance Metrics\n",
        "- Mean Cross-Validation Score: {:.4f} (+/- {:.4f})\n",
        "- Cross-Validation Scores: {}\n",
        "\n",
        "## 2. Model Configuration\n",
        "### Base Model Parameters:\n",
        "- Number of Trees (n_estimators): {}\n",
        "- Maximum Depth: {}\n",
        "- Number of CPU Cores Used: {}\n",
        "\n",
        "\"\"\".format(\n",
        "            cv_scores.mean(),\n",
        "            cv_scores.std() * 2,\n",
        "            [f\"{score:.4f}\" for score in cv_scores],\n",
        "            model.n_estimators,\n",
        "            model.max_depth,\n",
        "            self.n_jobs\n",
        "        )\n",
        "\n",
        "        if best_params:\n",
        "            report += \"\"\"\n",
        "### Optimized Parameters:\n",
        "{}\n",
        "\"\"\".format('\\n'.join([f\"- {k}: {v}\" for k, v in best_params.items()]))\n",
        "\n",
        "        # Lưu report\n",
        "        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "        report_path = f'model_evaluation_{timestamp}.md'\n",
        "        with open(report_path, 'w') as f:\n",
        "            f.write(report)\n",
        "\n",
        "        self.logger.info(f\"Evaluation report saved to {report_path}\")\n",
        "        return report\n",
        "\n",
        "    # load data thành tập train và test\n",
        "    def load_data(self, train_file: str, test_file: str, sample_fraction: float = 0.1) -> tuple:\n",
        "        try:\n",
        "            df_train = pd.read_csv(train_file)\n",
        "            df_test = pd.read_csv(test_file)\n",
        "\n",
        "            if 'Label' not in df_train.columns:\n",
        "                raise ValueError(\"Training data must contain 'Label' column\")\n",
        "\n",
        "            train_features = set(df_train.columns) - {'Label'}\n",
        "            test_features = set(df_test.columns)\n",
        "            if train_features != test_features:\n",
        "                raise ValueError(\"Training and test data must have matching features\")\n",
        "\n",
        "            self.logger.info(f\"Loaded training data shape: {df_train.shape}\")\n",
        "            self.logger.info(f\"Loaded test data shape: {df_test.shape}\")\n",
        "\n",
        "            return df_train, df_test\n",
        "\n",
        "        except FileNotFoundError as e:\n",
        "            self.logger.error(f\"File not found: {e}\")\n",
        "            raise\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error loading data: {e}\")\n",
        "            raise\n",
        "\n",
        "    # tiền xử lý data\n",
        "    def preprocess_data(self, df: pd.DataFrame, scaler=None, label_encoder=None,\n",
        "                        is_training=True) -> tuple:\n",
        "        try:\n",
        "            df = df.copy()\n",
        "\n",
        "            # Xác định loại cột\n",
        "            numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "            categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "            # Xử lý missing values cho từng loại dữ liệu\n",
        "            # Numeric: điền bằng median\n",
        "            for col in numeric_cols:\n",
        "                if is_training:\n",
        "                    median_val = df[col].median()\n",
        "                    df[col] = df[col].fillna(median_val)\n",
        "                    if hasattr(self, f'median_{col}'):\n",
        "                        setattr(self, f'median_{col}', median_val)\n",
        "                else:\n",
        "                    if hasattr(self, f'median_{col}'):\n",
        "                        df[col] = df[col].fillna(getattr(self, f'median_{col}'))\n",
        "                    else:\n",
        "                        df[col] = df[col].fillna(0)\n",
        "\n",
        "            # Categorical: điền bằng mode\n",
        "            for col in categorical_cols:\n",
        "                if is_training:\n",
        "                    mode_val = df[col].mode()[0]\n",
        "                    df[col] = df[col].fillna(mode_val)\n",
        "                    if hasattr(self, f'mode_{col}'):\n",
        "                        setattr(self, f'mode_{col}', mode_val)\n",
        "                else:\n",
        "                    if hasattr(self, f'mode_{col}'):\n",
        "                        df[col] = df[col].fillna(getattr(self, f'mode_{col}'))\n",
        "                    else:\n",
        "                        df[col] = df[col].fillna('Unknown')\n",
        "\n",
        "            # Chuyển đổi dữ liệu phân loại (chuỗi) thành số\n",
        "            for col in categorical_cols:\n",
        "                if is_training:\n",
        "                    le = LabelEncoder()\n",
        "                    df[col] = le.fit_transform(df[col].astype(str))\n",
        "                    if hasattr(self, f'le_{col}'):\n",
        "                        setattr(self, f'le_{col}', le)\n",
        "                else:\n",
        "                    if hasattr(self, f'le_{col}'):\n",
        "                        le = getattr(self, f'le_{col}')\n",
        "                        df[col] = df[col].astype(str)\n",
        "                        # Handle unseen categories\n",
        "                        df[col] = df[col].map(lambda x: 'Unknown' if x not in le.classes_ else x)\n",
        "                        df[col] = le.transform(df[col])\n",
        "                    else:\n",
        "                        df[col] = df[col].astype('category').cat.codes\n",
        "\n",
        "            # Chuyển đổi dữ liệu sang float32 để tối ưu bộ nhớ\n",
        "            for col in numeric_cols:\n",
        "                df[col] = df[col].astype('float32')\n",
        "\n",
        "            if is_training:\n",
        "                X = df.drop('Label', axis=1)\n",
        "                y = df['Label']\n",
        "\n",
        "                label_encoder = LabelEncoder()\n",
        "                scaler = StandardScaler()\n",
        "\n",
        "                # Sử dụng StandardScaler để chuẩn hóa dữ liệu\n",
        "                y = label_encoder.fit_transform(y)\n",
        "                X = scaler.fit_transform(X)\n",
        "\n",
        "                self.logger.info(f\"Preprocessed training data shape: {X.shape}\")\n",
        "                return X, y, scaler, label_encoder\n",
        "            else:\n",
        "                X = scaler.transform(df)\n",
        "                self.logger.info(f\"Preprocessed test data shape: {X.shape}\")\n",
        "                return X, None\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in preprocessing: {e}\")\n",
        "            raise\n",
        "\n",
        "    def train_random_forest(self, X: np.ndarray, y: np.ndarray) -> tuple:\n",
        "        try:\n",
        "            # chia dữ liệu\n",
        "            X_train, X_val, y_train, y_val = train_test_split(\n",
        "                X, y, test_size=0.2, random_state=self.random_state\n",
        "            )\n",
        "\n",
        "            #n_estimators=100: Số cây trong rừng\n",
        "            #max_depth=30: Độ sâu tối đa của cây\n",
        "            #warm_start=True: Tiếp tục huấn luyện từ trạng thái trước đó\n",
        "            #Sử dụng 80% dữ liệu huấn luyện được sử dụng để huấn luyện từng cây, giúp giảm tương quan giữa các cây.\n",
        "            model = RandomForestClassifier(\n",
        "                n_estimators=100,\n",
        "                random_state=self.random_state,\n",
        "                n_jobs=self.n_jobs,\n",
        "                verbose=1,\n",
        "                max_depth=30,\n",
        "                max_samples=0.8,\n",
        "                warm_start=True\n",
        "            )\n",
        "\n",
        "            # Cross-validation\n",
        "            with warnings.catch_warnings():\n",
        "                warnings.simplefilter(\"ignore\")\n",
        "                cv_scores = cross_val_score(\n",
        "                    model, X, y,\n",
        "                    cv=5,\n",
        "                    n_jobs=self.n_jobs,\n",
        "                    verbose=1\n",
        "                )\n",
        "\n",
        "            self.logger.info(f\"CV Scores: {cv_scores}\")\n",
        "            self.logger.info(f\"Mean CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
        "\n",
        "            # Huấn luyện mô hình\n",
        "            model.fit(X_train, y_train)\n",
        "\n",
        "            # Dự đoán trên tập đánh giá bằng accuracy\n",
        "            val_predictions = model.predict(X_val)\n",
        "            val_accuracy = accuracy_score(y_val, val_predictions)\n",
        "\n",
        "            self.logger.info(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
        "            self.logger.info(\"\\nClassification Report:\")\n",
        "            self.logger.info(classification_report(y_val, val_predictions))\n",
        "\n",
        "            # tạo report\n",
        "            self.generate_evaluation_report(model, cv_scores)\n",
        "\n",
        "            return model, cv_scores.mean()\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in training: {e}\")\n",
        "            raise\n",
        "\n",
        "    def optimize_random_forest(self, X: np.ndarray, y: np.ndarray) -> RandomForestClassifier:\n",
        "        try:\n",
        "            # Các tham số có thể tối ưu:\n",
        "            #n_estimators: Số lượng cây cần thử: 200\n",
        "            #max_depth: Giới hạn độ sâu của cây: 20 hoặc không giới hạn\n",
        "            #min_samples_split: Số lượng mẫu tối thiểu cần có để tránh overfitting: 5\n",
        "            #min_samples_leaf: Số lượng mẫu tối thiểu cần có trong một lá: 2\n",
        "            #max_features: Số lượng đặc trưng tối đa xem xét khi tách tại mỗi node\n",
        "            #'sqrt' được sử dụng để tăng tốc và giảm tương quan giữa các cây.\n",
        "            param_grid = {\n",
        "                'n_estimators': [200],\n",
        "                'max_depth': [20, None],\n",
        "                'min_samples_split': [5],\n",
        "                'min_samples_leaf': [2],\n",
        "                'max_features': ['sqrt']\n",
        "            }\n",
        "\n",
        "            base_model = RandomForestClassifier(\n",
        "                random_state=self.random_state,\n",
        "                n_jobs=self.n_jobs,\n",
        "                verbose=1\n",
        "            )\n",
        "\n",
        "            # Thử nghiệm từng tham số trong param_grid bằng cách sử dụng cross-validation với 3 fold.\n",
        "            grid_search = GridSearchCV(\n",
        "                base_model,\n",
        "                param_grid,\n",
        "                cv=3,\n",
        "                n_jobs=self.n_jobs,\n",
        "                scoring='accuracy',\n",
        "                verbose=2\n",
        "            )\n",
        "\n",
        "            # Huấn luyện mô hình với tất cả tham số trong param_grid và chọn ra tham số tốt nhất\n",
        "            grid_search.fit(X, y)\n",
        "\n",
        "            self.logger.info(f\"Best parameters: {grid_search.best_params_}\")\n",
        "            self.logger.info(f\"Best cross-validation accuracy: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "            # Tạo report\n",
        "            self.generate_evaluation_report(\n",
        "                grid_search.best_estimator_,\n",
        "                cross_val_score(grid_search.best_estimator_, X, y, cv=5),\n",
        "                grid_search.best_params_\n",
        "            )\n",
        "\n",
        "            return grid_search.best_estimator_\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in optimization: {e}\")\n",
        "            raise\n",
        "\n",
        "    # Lưu các thành phần quan trọng của pipeline (mô hình, scaler, label encoder, và dự đoán) vào các tệp\n",
        "    def save_artifacts(self, model, scaler, label_encoder, predictions,\n",
        "                       predictions_labels, output_dir='outputs'):\n",
        "        try:\n",
        "            output_dir = Path(output_dir)\n",
        "            output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "            timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "\n",
        "            joblib.dump(model,\n",
        "                        output_dir / f'model_{timestamp}.joblib',\n",
        "                        compress=3)\n",
        "            joblib.dump(scaler,\n",
        "                        output_dir / f'scaler_{timestamp}.joblib',\n",
        "                        compress=3)\n",
        "            joblib.dump(label_encoder,\n",
        "                        output_dir / f'label_encoder_{timestamp}.joblib',\n",
        "                        compress=3)\n",
        "\n",
        "            results_df = pd.DataFrame({\n",
        "                'Predicted_Label_Encoded': predictions,\n",
        "                'Predicted_Label': predictions_labels\n",
        "            })\n",
        "            results_df.to_csv(output_dir / f'predictions_{timestamp}.csv',\n",
        "                              index=False)\n",
        "\n",
        "            self.logger.info(f\"All artifacts saved to {output_dir}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error saving artifacts: {e}\")\n",
        "            raise\n",
        "\n",
        "    def run_pipeline(self, train_file: str, test_file: str, output_dir='outputs'):\n",
        "        try:\n",
        "            self.logger.info(\"Starting ML pipeline\")\n",
        "\n",
        "            # load dữ liệu train và test\n",
        "            df_train, df_test = self.load_data(train_file, test_file)\n",
        "\n",
        "            # tiền xử lý dữ liệu train\n",
        "            X_train, y_train, scaler, label_encoder = self.preprocess_data(\n",
        "                df_train, is_training=True\n",
        "            )\n",
        "\n",
        "            # train model\n",
        "            model, base_score = self.train_random_forest(X_train, y_train)\n",
        "\n",
        "            # optimize model\n",
        "            best_model = self.optimize_random_forest(X_train, y_train)\n",
        "\n",
        "            # tiền xử lý dữ liệu test\n",
        "            X_test, _ = self.preprocess_data(\n",
        "                df_test, scaler, label_encoder, is_training=False\n",
        "            )\n",
        "\n",
        "            # thực hiện dự đoán trên tập test\n",
        "            predictions = best_model.predict(X_test)\n",
        "            predictions_labels = label_encoder.inverse_transform(predictions)\n",
        "\n",
        "            # lưu tham số\n",
        "            self.save_artifacts(\n",
        "                best_model, scaler, label_encoder,\n",
        "                predictions, predictions_labels, output_dir\n",
        "            )\n",
        "\n",
        "            return best_model, scaler, label_encoder\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Pipeline failed: {e}\")\n",
        "            raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Khởi động và chạy toàn bộ pipeline Machine Learning (MLPipeline) từ dữ liệu đầu vào cho đến kết quả cuối cùng."
      ],
      "metadata": {
        "id": "J86R9VpzoucU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    n_jobs = max(os.cpu_count() // 2, 1)\n",
        "\n",
        "    # Khởi tạo và chạy pipeline\n",
        "    pipeline = MLPipeline(n_jobs=n_jobs)\n",
        "    try:\n",
        "        best_model, scaler, label_encoder = pipeline.run_pipeline(\n",
        "            train_file='drive/MyDrive/ML/RandomForest/train.csv',\n",
        "            test_file='drive/MyDrive/ML/RandomForest/test.csv'\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Pipeline failed: {e}\")"
      ],
      "metadata": {
        "id": "ZBFI8tApoo6o"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}